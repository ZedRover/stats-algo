{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib # A must \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection as skms\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from time import sleep\n",
    "%matplotlib inline\n",
    "#Built-in magic commands: the IPython kernel uses the % syntax element for Magics\n",
    "#Roughly, it is equivalent to invoking a shell function\n",
    "#Not supported by PyCharm, for instance\n",
    "#Instead of putting plt.show() at the end of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, \n",
    "                       columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification task\n",
    "\n",
    "  * Building learning systems\n",
    "  * Evaluating learning systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary classification** If there are only two target classes for output, we can call a learning task *binary classification*.\n",
    "\n",
    "  * {Yes, No}\n",
    "  * {Red, Blue}\n",
    "  * {True, False}\n",
    "  \n",
    "Computer scientists / Mathematicians\n",
    "\n",
    "  * {-1, 1}\n",
    "  * {0, 1}\n",
    "  \n",
    "With more than two target classes, we have a *multiclass* problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Testing** \n",
    "\n",
    "Back to class room setting. A common way of evaluating students is to teach some materials and then test them.\n",
    "\n",
    "Studying: Training the learner\n",
    "Evaluation: Giving test to the learner, evaluating on its output\n",
    "\n",
    "  * If the problems in the test are taught?\n",
    "\n",
    "Test should be based on general knowledge and techniques. Basically, the problems in the test should be all novel. The performance on unseen examples is called generalization. If test on data we have already seen, then -- *overfitting*\n",
    "\n",
    "However, we have never an answer to the target feature to be predicted. Thus, to evaluate the earning machine, we perform a so-called *in-sample evaluation* (or estimation on training error). How? splitting the examples.\n",
    "\n",
    "The function \"train_test_split\" in the package \"model_selection\" from \"sklearn\" segments our datasets.\n",
    "\n",
    "Fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mskms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Split arrays or matrices into random train and test subsets\n",
      "\n",
      "Quick utility that wraps input validation and\n",
      "``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "into a single call for splitting (and optionally subsampling) data in a\n",
      "oneliner.\n",
      "\n",
      "Read more in the :ref:`User Guide <cross_validation>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "*arrays : sequence of indexables with same length / shape[0]\n",
      "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "    matrices or pandas dataframes.\n",
      "\n",
      "test_size : float or int, default=None\n",
      "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "    of the dataset to include in the test split. If int, represents the\n",
      "    absolute number of test samples. If None, the value is set to the\n",
      "    complement of the train size. If ``train_size`` is also None, it will\n",
      "    be set to 0.25.\n",
      "\n",
      "train_size : float or int, default=None\n",
      "    If float, should be between 0.0 and 1.0 and represent the\n",
      "    proportion of the dataset to include in the train split. If\n",
      "    int, represents the absolute number of train samples. If None,\n",
      "    the value is automatically set to the complement of the test size.\n",
      "\n",
      "random_state : int or RandomState instance, default=None\n",
      "    Controls the shuffling applied to the data before applying the split.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "    then stratify must be None.\n",
      "\n",
      "stratify : array-like, default=None\n",
      "    If not None, data is split in a stratified fashion, using this as\n",
      "    the class labels.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "splitting : list, length=2 * len(arrays)\n",
      "    List containing train-test split of inputs.\n",
      "\n",
      "    .. versionadded:: 0.16\n",
      "        If the input is sparse, the output will be a\n",
      "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "        input type.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.model_selection import train_test_split\n",
      ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      ">>> X\n",
      "array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5],\n",
      "       [6, 7],\n",
      "       [8, 9]])\n",
      ">>> list(y)\n",
      "[0, 1, 2, 3, 4]\n",
      "\n",
      ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "...     X, y, test_size=0.33, random_state=42)\n",
      "...\n",
      ">>> X_train\n",
      "array([[4, 5],\n",
      "       [0, 1],\n",
      "       [6, 7]])\n",
      ">>> y_train\n",
      "[2, 0, 3]\n",
      ">>> X_test\n",
      "array([[2, 3],\n",
      "       [8, 9]])\n",
      ">>> y_test\n",
      "[1, 4]\n",
      "\n",
      ">>> train_test_split(y, shuffle=False)\n",
      "[[0, 1, 2], [3, 4]]\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/model_selection/_split.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "from sklearn import model_selection as skms\n",
    "skms.train_test_split?\n",
    "#type(iris.data)\n",
    "#type(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train features shape: (75, 4)\nTest features shape: (75, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5.5, 4.2, 1.4, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [5.6, 2.8, 4.9, 2. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# simple train/test split\n",
    "(iris_train_ftrs, iris_test_ftrs, \n",
    " iris_train_tgt,  iris_test_tgt) = skms.train_test_split(iris.data,\n",
    "                                                         iris.target, \n",
    "                                                         test_size=.50)\n",
    "print(\"Train features shape:\", iris_train_ftrs.shape)\n",
    "print(\"Test features shape:\",  iris_test_ftrs.shape)\n",
    "type(iris_train_ftrs)\n",
    "#type(iris_test_ftrs)\n",
    "iris_train_ftrs #Typically we sort data into training and testing randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation: Grading**\n",
    "\n",
    "Design our evaluation : 4 cases\n",
    "\n",
    "  * answer is true / predicted to be true (1 point)\n",
    "  * answer is false / predicted to be false (1 point)\n",
    "  * answer is true / predicted to be false (0 point)\n",
    "  * answer is true / predicted to be true (1 point)\n",
    "  \n",
    "Evaluation of *accuracy*\n",
    "\n",
    "$$\n",
    "\\frac{{\\rm number\\ of\\ correct\\ answers}}{{\\rm number\\ of\\ questions}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_key = np.array([True, True, False, True]) # solutions to the exam;)))\n",
    "student_answers = np.array([True, True, True, True]) # a student's answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ True  True False  True]\nmanual accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "correct = answer_key == student_answers # mark each answer right or wrong\n",
    "print(correct)\n",
    "num_correct = correct.sum() # True == 1, add up the right answers\n",
    "print(\"manual accuracy:\", num_correct / len(answer_key)) # calculate the percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sklearn accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"sklearn accuracy:\", \n",
    "      metrics.accuracy_score(answer_key, \n",
    "                             student_answers)) # solutions v.s. a student's answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple classifier: nearest neighbors**\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"0.jpeg\" width=200/>\n",
    "    <img src=\"1.jpeg\" width=200/>\n",
    "    <img src=\"3.jpeg\" width=200/>\n",
    "    <img src=\"5.jpeg\" width=200/>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "One of the simplest ideas for making predictions from a labeled dataset.\n",
    "\n",
    "To predict the label of an unknown example:\n",
    "\n",
    "  * Find a way to describe the similarity of two different examples\n",
    "  * Take the value from the most similar known example to predict the label of the unknown example\n",
    "  \n",
    "Think a little bit more:\n",
    "\n",
    "  * Similarity\n",
    "  * More similar examples\n",
    "  * A single answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarity** \n",
    "\n",
    "A natural idea: measuring first the distance between two examples, that is \n",
    "\n",
    "similarity = distance (features of example_one, features of example_2)\n",
    "\n",
    "  * When features are all numbers : Minkowski distance $d_{12} = \\sqrt[p]{\\sum^n_{k=1} |x_{1k}-x_{2k}|^p}$;\n",
    "  \n",
    "    * $p=1$, Manhattan distance;\n",
    "    * $p=2$, Euclidean distance;\n",
    "    * $p=\\infty$, Chebyshev distance.\n",
    "    \n",
    "  * When features are like {True, False} or {Yes, No}\n",
    "  \n",
    "    * Hamming distance measuring the difference (recall the accuracy)\n",
    "    \n",
    "   $$\n",
    "   \\frac{{\\rm number\\ of\\ different\\ features}}{{\\rm number\\ of\\ features}}\n",
    "   $$\n",
    "   \n",
    "Mathematically, distance is a metric (Pythagorean theorem).\n",
    "\n",
    "In \"sklearn\", \"neighbors.DistanceMetric\" is a distance calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.        , 4.00390054],\n",
       "       [4.00390054, 0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "#neighbors.DistanceMetric?\n",
    "#dist=neighbors.DistanceMetric.get_metric('euclidean')\n",
    "dist=neighbors.DistanceMetric.get_metric('minkowski', p=4)\n",
    "#dist=neighbors.DistanceMetric.get_metric('hamming')\n",
    "X=np.array([[1, 1, 4],[1, 2, 8]])\n",
    "dist.pairwise(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN-C and KNN-R**\n",
    "\n",
    "Instead considering only the nearest neighbor, we might consider some small number of nearby neighbors. Why? \n",
    "\n",
    "Common numbers of neighbors are 1, 3, 10 or 20. \n",
    "\n",
    "How to combine the different opinions in the neighborhood?\n",
    "\n",
    "  * Classification: the most frequent response\n",
    "  * Regression: mean? median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 0 2 0 2 1 0 2 0 1 0 0 0 2 0 2 1 2 2 1 2 1 0 0 1 2 2 1 2 1 2 1 2 1 2 2 0\n 2 1 0 1 0 2 2 1 2 1 2 2 0 0 1 1 0 1 0 0 1 1 2 1 2 0 0 1 2 2 0 1 1 2 0 0 2\n 0]\n3NN accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Build a k-NN classification model \n",
    "# Supervised model\n",
    "# Capture the relationship between input features and output tagets\n",
    "# default n_neighbors = 5\n",
    "knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "fit   = knn.fit(iris_train_ftrs, iris_train_tgt) # Fit the model to on training data, no return value\n",
    "preds = fit.predict(iris_test_ftrs) # Use that model to predict on the test data\n",
    "print(preds)\n",
    "# evaluate our predictions against the held-back testing targets\n",
    "print(\"3NN accuracy:\", \n",
    "      metrics.accuracy_score(iris_test_tgt, preds)) #Evaluate those predictions using accuracy\n",
    "# This machine learning stuff seems pretty easy\n",
    "#neighbors.KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard procedures**\n",
    "\n",
    "  * Build the model (3-NN)\n",
    "  * Fit the model (knn.fit)\n",
    "  * Predict use the fit model (knn.fit.predict)\n",
    "  * Evaluate the quality of the predictions (accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameteric methods v.s. nonparametric methods**\n",
    "\n",
    "KNN is a nonparametric method. Thinking about a question: what will happen if we increase the number of examples from 100 to 101?\n",
    "\n",
    "All of the training examples will affect outputs. (machine with 100 knobs v.s. machine with 101 knobs). Example?\n",
    "\n",
    "With more informaiton (more training data), the knobs of the machine is growing. \n",
    "\n",
    "In contrast to nonparametric methods, parametric methods use a fixed number of parameters to caputre the relationship between input features and target features. \n",
    "\n",
    "What is the so-called $k$? a hyperparameter -- a parameter is not trained or manipulated by the learning method that it helps define (a fixed set of rules)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple classifier: Naive Bayes**\n",
    "\n",
    "KNN is a so-called *discriminative model*. With a discriminative model, roughly speaking, the learner studies directly the discriminative function $Y=f(X)$, or equivalently, studies the conditional probability $P(Y|X)$ and gives its prediction by \n",
    "\n",
    "$$\n",
    "\\widehat{y}=\\widehat{f}(x)=argmax_{y=c_1, c_2, \\ldots, c_K} P(Y=c_k | X=x).\n",
    "$$ \n",
    "\n",
    "Another type of model is called *generative model*. With a generative model (possibly with latent variables), the learner studies the joint probability distribution $P(X, Y)$ and then conditional law is established by the so-called Bayes rule:\n",
    "\n",
    "$$\n",
    "P(Y=c_k|X=x) = \\frac{P(X=x, Y=c_k)}{P(X=x)} = \\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_k P(X=x|Y=c_k)P(Y=c_k)},\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "P(X=x)=P(X^{(1)}=x^{(1)}, X^{(2)}=x^{(2)}, \\ldots, X^{(n)}=x^{(n)}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes (NB)**\n",
    "\n",
    "At casino, you may sit down at a fair table or at a rigged table. At either table, you can play a dice game or a card game. \n",
    "\n",
    "At a rigged table\n",
    "\n",
    "  * the dice you roll is teaked. It comes up with 6 pips one time in eleven and with 1, 2, 3, 4, 5 at the probability 2/11;\n",
    "  * No K, Q, J cards on the rigged table.\n",
    "  \n",
    "If you know which table you are at, for instance, at the rigged table, you won't expect to see 6 pips often; you won't expect that K, Q, J cards occur.\n",
    "\n",
    "However, if you are blindfolded and led to a table. You sit down and the blindfold is removed. Then you only could guess which table you are by the outcomes of the dice and the card. For instance, if K occurs then you should be at the fair table. \n",
    "\n",
    "  * If you don't know which table then from playing card you get information about the dice\n",
    "  * If you have already known the table, playing card will not tells us additional information about the dice\n",
    "  \n",
    "That is to say, no communication or causation between the dice and the cards at one of the tables.  Mathematically, the cards and the dice are *conditionally independent given the table*. That is the scenario lets us discuss the main ideas of Naive Bayes (NB).\n",
    "\n",
    "In Naive Bayes model, we adopt the so-called *Naive Bayes assumption*. By this assumption, we have \n",
    "\n",
    "$$\n",
    "P(X=x|y=c_k) = P(X^{(1)}=x^{(1)}, X^{(2)}=x^{(2)}, \\ldots, X^{(n)}=x^{(n)}|y=c_k) = \\Pi^n_{j=1} P(X^{(j)}=x^{(j)}|y=c_k).\n",
    "$$\n",
    "\n",
    "Indeed, in practice, the emprical probablity \n",
    "\n",
    "$$\n",
    "P(X^{(j)}=x^{(j)}|Y=c_k)\\ {\\rm and}\\ P(Y=c_k),\n",
    "$$\n",
    "\n",
    "is estimated by \n",
    "\n",
    "$$\n",
    "P(X^{(j)}=x^{(j)}|Y=c_k) = \\frac{\\#{\\rm examples\\ with}\\ j{\\rm th\\ input}\\ x^{(j)}\\ {\\rm and\\ output\\ feature}\\ c_k}{\\#{\\rm examples\\ with\\ output\\ feature}\\ c_k}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "P(Y=c_k)= \\frac{\\#{\\rm examples\\ with\\ output\\ feature}\\ c_k}{\\#{\\rm examples}}.\n",
    "$$\n",
    "\n",
    "This estimate is a maximum likelihood estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB model v.s. loss function**\n",
    "\n",
    "NB classification predicts that \n",
    "\n",
    "$$\n",
    "\\widehat{y}=\\widehat{f}(x)=argmax_{y=c_1, c_2, \\ldots, c_K} P(Y=c_k | X=x).\n",
    "$$ \n",
    "\n",
    "This is equivalent to the minimization of the expected risk function. Indeed, consider the $0-1$ loss function. Then the expected risk function \n",
    "\n",
    "$$\n",
    "R_{exp}(f) = E[L(Y, f(X))] = E_X[\\sum^K_{k=1}L(c_k, f(X))]P(c_k|X).\n",
    "$$\n",
    "\n",
    "To minimize the above function, it is to minimize individually the function $R_exp$ for each $X=x$. That is \n",
    "\n",
    "\\begin{align*}\n",
    "f(x) &= {\\rm argmin}_{y = c_1, c_2, \\ldots, c_K} \\sum^K_{k=1} L(c_k, y) P(c_k |X=x) \\\\\n",
    "& = {\\rm argmin}_{y = c_1, c_2, \\ldots, c_K} \\sum^K_{k=1} P(y\\neq c_k|X=x)\\\\\n",
    "& = {\\rm argmin}_{y = c_1, c_2, \\ldots, c_K} (1-P(y=c_k|X=x))\\\\\n",
    "& = {\\rm argmax}_{y = c_1, c_2, \\ldots, c_K} P(y=c_k|X=x).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB accuracy: 0.9733333333333334\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-09\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Gaussian Naive Bayes (GaussianNB)\n",
      "\n",
      "Can perform online updates to model parameters via :meth:`partial_fit`.\n",
      "For details on algorithm used to update feature means and variance online,\n",
      "see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
      "\n",
      "    http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n",
      "\n",
      "Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "priors : array-like of shape (n_classes,)\n",
      "    Prior probabilities of the classes. If specified the priors are not\n",
      "    adjusted according to the data.\n",
      "\n",
      "var_smoothing : float, default=1e-9\n",
      "    Portion of the largest variance of all features that is added to\n",
      "    variances for calculation stability.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "class_count_ : ndarray of shape (n_classes,)\n",
      "    number of training samples observed in each class.\n",
      "\n",
      "class_prior_ : ndarray of shape (n_classes,)\n",
      "    probability of each class.\n",
      "\n",
      "classes_ : ndarray of shape (n_classes,)\n",
      "    class labels known to the classifier\n",
      "\n",
      "epsilon_ : float\n",
      "    absolute additive value to variances\n",
      "\n",
      "sigma_ : ndarray of shape (n_classes, n_features)\n",
      "    variance of each feature per class\n",
      "\n",
      "theta_ : ndarray of shape (n_classes, n_features)\n",
      "    mean of each feature per class\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      ">>> Y = np.array([1, 1, 1, 2, 2, 2])\n",
      ">>> from sklearn.naive_bayes import GaussianNB\n",
      ">>> clf = GaussianNB()\n",
      ">>> clf.fit(X, Y)\n",
      "GaussianNB()\n",
      ">>> print(clf.predict([[-0.8, -1]]))\n",
      "[1]\n",
      ">>> clf_pf = GaussianNB()\n",
      ">>> clf_pf.partial_fit(X, Y, np.unique(Y))\n",
      "GaussianNB()\n",
      ">>> print(clf_pf.predict([[-0.8, -1]]))\n",
      "[1]\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/naive_bayes.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "nb    = naive_bayes.GaussianNB()\n",
    "fit   = nb.fit(iris_train_ftrs, iris_train_tgt)\n",
    "preds = fit.predict(iris_test_ftrs)\n",
    "\n",
    "print(\"NB accuracy:\", \n",
    "      metrics.accuracy_score(iris_test_tgt, preds))\n",
    "naive_bayes.GaussianNB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kNN: 1.00\n NB: 1.00\n"
     ]
    }
   ],
   "source": [
    "# stand alone code\n",
    "from sklearn import (datasets, metrics, \n",
    "                     model_selection as skms,\n",
    "                     naive_bayes, neighbors)\n",
    "\n",
    "# we set random_state so the results are reproducable\n",
    "# otherwise, we get different training and testing sets\n",
    "# more details in Chapter 5\n",
    "iris = datasets.load_iris()\n",
    "(iris_train_ftrs, iris_test_ftrs, \n",
    " iris_train_tgt, iris_test_tgt) = skms.train_test_split(iris.data,\n",
    "                                                        iris.target, \n",
    "                                                        test_size=.20,\n",
    "                                                        random_state=42) \n",
    "\n",
    "models = {'kNN': neighbors.KNeighborsClassifier(n_neighbors=3),\n",
    "          'NB' : naive_bayes.GaussianNB()}\n",
    "\n",
    "for name, model in models.items():\n",
    "    fit = model.fit(iris_train_ftrs, iris_train_tgt)\n",
    "    predictions = fit.predict(iris_test_ftrs)\n",
    "    \n",
    "    score = metrics.accuracy_score(iris_test_tgt, predictions)\n",
    "    print(\"{:>3s}: {:0.2f}\".format(name,score)) #:>3 and 0.2f are regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resource utilization in classification**\n",
    "\n",
    "We talk about the cost of a program or an alogorithm in terms of processing time and memory.\n",
    "\n",
    "  * We are not in the years of 1960s\n",
    "  * Big data\n",
    "  * GPUs (Graphics processing units) \n",
    "  \n",
    "If you don't have a small data and the problem is a little bit large which could not be solved on your laptop in a reasonable amount of time, then you could sip a majito under a palm. However, it is impossible if you are a developer of a commercial software.\n",
    "\n",
    "Doubing available memory won't alway's double the size of the dataset I can process. \n",
    "\n",
    "Two ways to study:\n",
    "\n",
    "  * Algorithm analysis: develop equations that relate the time and memory use of a computing task to the size of the task's input. For example, a method will take $2n+87$ steps on $n$ imput examples. This is tooooo theoretical and is out of the scope of this lecture.\n",
    "  * Running an algorithm and measuring the cost on the resources will be a practical way. Be careful, everything occurring on your system can potentially have a significant impact on your learning systems resource utilization. \n",
    "  \n",
    "Units:\n",
    "\n",
    "  * time: second (s)\n",
    "  * memory: Byte (B). 1Byte = 8bytes. 8 bits can distinguish between 256 different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.29 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1\n",
    "a=2\n",
    "for i in range(3):\n",
    "  a=a**1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.2 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1\n",
    "sleep(0.001)\n",
    "# %%make a cell magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "897 µs ± 15.3 µs per loop (mean ± std. dev. of 10 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r10 datasets.load_iris()\n",
    "# %make a line magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "261 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n10\n",
    "# -r1: run onece -n10: 10 loops each\n",
    "(iris_train_ftrs, iris_test_ftrs, \n",
    " iris_train_tgt,  iris_test_tgt) = skms.train_test_split(iris.data,\n",
    "                                                         iris.target, \n",
    "                                                         test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "771 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1\n",
    "\n",
    "nb    = naive_bayes.GaussianNB()\n",
    "fit   = nb.fit(iris_train_ftrs, iris_train_tgt)\n",
    "preds = fit.predict(iris_test_ftrs)\n",
    "\n",
    "metrics.accuracy_score(iris_test_tgt, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.81 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1\n",
    "\n",
    "knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "fit   = knn.fit(iris_train_ftrs, iris_train_tgt)\n",
    "preds = fit.predict(iris_test_ftrs)\n",
    "\n",
    "metrics.accuracy_score(iris_test_tgt, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "511 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n",
      "288 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# fitting\n",
    "nb = naive_bayes.GaussianNB()\n",
    "%timeit -r1 fit   = nb.fit(iris_train_ftrs, iris_train_tgt)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "%timeit -r1 fit = knn.fit(iris_train_ftrs, iris_train_tgt)\n",
    "# KNN takes slightly less time in fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "141 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10000 loops each)\n",
      "1.3 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# predicting\n",
    "nb    = naive_bayes.GaussianNB()\n",
    "fit   = nb.fit(iris_train_ftrs, iris_train_tgt)\n",
    "%timeit -r1 preds = fit.predict(iris_test_ftrs)\n",
    "\n",
    "knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "fit   = knn.fit(iris_train_ftrs, iris_train_tgt)\n",
    "%timeit -r1 preds = fit.predict(iris_test_ftrs)\n",
    "# KNN takes more time in predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n",
      "Requirement already satisfied: psutil in /Users/zed/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages (from memory_profiler) (5.7.2)\n",
      "Building wheels for collected packages: memory-profiler\n",
      "  Building wheel for memory-profiler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30183 sha256=fbace43789f1151a430580b36b1c1598959898cbf52108f40caf66344a10929f\n",
      "  Stored in directory: /Users/zed/Library/Caches/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n",
      "Successfully built memory-profiler\n",
      "Installing collected packages: memory-profiler\n",
      "Successfully installed memory-profiler-0.58.0\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler \n",
    "# or conda\n",
    "# install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "peak memory: 531.18 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "nb    = naive_bayes.GaussianNB()\n",
    "fit   = nb.fit(iris_train_ftrs, iris_train_tgt)\n",
    "preds = fit.predict(iris_test_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "peak memory: 531.18 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "fit   = knn.fit(iris_train_ftrs, iris_train_tgt)\n",
    "preds = fit.predict(iris_test_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "peak memory: 572.92 MiB, increment: 41.74 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "a=2\n",
    "for i in range(3):\n",
    "  a=a**1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib # A must \nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn import model_selection as skms\nfrom sklearn import metrics\nfrom sklearn import neighbors\nfrom sklearn import naive_bayes\nfrom time import sleep\n\nimport memory_profiler, sys\n\n@memory_profiler.profile(precision=4) #decorator\ndef knn_memtest(train, train_tgt, test):\n    knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n    fit   = knn.fit(train, train_tgt)\n    preds = fit.predict(test)\n\nif __name__ == \"__main__\":\n    iris = datasets.load_iris()\n    tts = skms.train_test_split(iris.data,\n                                iris.target,\n                               test_size=.25)\n    (iris_train_ftrs, iris_test_ftrs,\n     iris_train_tgt,  iris_test_tgt) = tts\n    tup = (iris_train_ftrs, iris_train_tgt, iris_test_ftrs)\n    knn_memtest(*tup)\n"
     ]
    }
   ],
   "source": [
    "!cat scripts/knn_memtest.py\n",
    "#with window OS, instead of \"!cat\", use \"!type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filename: scripts/knn_memtest.py\n\nLine #    Mem usage    Increment  Occurences   Line Contents\n============================================================\n    15 132.0586 MiB 132.0586 MiB           1   @memory_profiler.profile(precision=4) #decorator\n    16                                         def knn_memtest(train, train_tgt, test):\n    17 132.0586 MiB   0.0000 MiB           1       knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n    18 132.1758 MiB   0.1172 MiB           1       fit   = knn.fit(train, train_tgt)\n    19 132.2852 MiB   0.1094 MiB           1       preds = fit.predict(test)\n\n\n"
     ]
    }
   ],
   "source": [
    "!python scripts/knn_memtest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib # A must \nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn import model_selection as skms\nfrom sklearn import metrics\nfrom sklearn import neighbors\nfrom sklearn import naive_bayes\nfrom time import sleep\n\nimport memory_profiler, sys\n\n@memory_profiler.profile(precision=4) #decorator\ndef knn_memtest(train, train_tgt, test):\n    knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n    fit   = knn.fit(train, train_tgt)\n    preds = fit.predict(test)\n\nif __name__ == \"__main__\":\n    iris = datasets.load_iris()\n    tts = skms.train_test_split(iris.data,\n                                iris.target,\n                               test_size=.25)\n    (iris_train_ftrs, iris_test_ftrs,\n     iris_train_tgt,  iris_test_tgt) = tts\n    tup = (iris_train_ftrs, iris_train_tgt, iris_test_ftrs)\n    knn_memtest(*tup)\n"
     ]
    }
   ],
   "source": [
    "!cat scripts/knn_memtest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nb_go: ~0.000000000 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib # A must \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection as skms\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from time import sleep\n",
    "\n",
    "import functools as ft\n",
    "import memory_profiler\n",
    "\n",
    "def nb_go(train_ftrs, test_ftrs, train_tgt):\n",
    "    nb    = naive_bayes.GaussianNB()\n",
    "    fit   = nb.fit(train_ftrs, train_tgt)\n",
    "    preds = fit.predict(test_ftrs)\n",
    "\n",
    "def split_data(dataset):\n",
    "    split = skms.train_test_split(dataset.data,\n",
    "                                  dataset.target,\n",
    "                                  test_size=.25)\n",
    "    return split[:-1] # don't need test tgt\n",
    "\n",
    "def msr_mem(go, args):\n",
    "    base = memory_profiler.memory_usage()[0]\n",
    "    mu = memory_profiler.memory_usage((go, args),\n",
    "                                       max_usage=True)\n",
    "    print(\"{:<3}: ~{:.9f} MiB\".format(go.__name__, mu-base))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    msr = msr_mem\n",
    "    go = nb_go\n",
    "\n",
    "    sd = split_data(datasets.load_iris())\n",
    "    msr(go, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmemory_profiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimestamps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minclude_children\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mretval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return the memory usage of a process or piece of code\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "proc : {int, string, tuple, subprocess.Popen}, optional\n",
      "    The process to monitor. Can be given by an integer/string\n",
      "    representing a PID, by a Popen object or by a tuple\n",
      "    representing a Python function. The tuple contains three\n",
      "    values (f, args, kw) and specifies to run the function\n",
      "    f(*args, **kw).\n",
      "    Set to -1 (default) for current process.\n",
      "\n",
      "interval : float, optional\n",
      "    Interval at which measurements are collected.\n",
      "\n",
      "timeout : float, optional\n",
      "    Maximum amount of time (in seconds) to wait before returning.\n",
      "\n",
      "max_usage : bool, optional\n",
      "    Only return the maximum memory usage (default False)\n",
      "\n",
      "retval : bool, optional\n",
      "    For profiling python functions. Save the return value of the profiled\n",
      "    function. Return value of memory_usage becomes a tuple:\n",
      "    (mem_usage, retval)\n",
      "\n",
      "timestamps : bool, optional\n",
      "    if True, timestamps of memory usage measurement are collected as well.\n",
      "\n",
      "include_children : bool, optional\n",
      "    if True, sum the memory of all forked processes as well\n",
      "\n",
      "multiprocess : bool, optional\n",
      "    if True, track the memory usage of all forked processes.\n",
      "\n",
      "stream : File\n",
      "    if stream is a File opened with write access, then results are written\n",
      "    to this file instead of stored in memory and returned at the end of\n",
      "    the subprocess. Useful for long-running processes.\n",
      "    Implies timestamps=True.\n",
      "\n",
      "max_iterations : int\n",
      "    Limits the number of iterations (calls to the process being monitored). Relevent\n",
      "    when the process is a python function.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "mem_usage : list of floating-point values\n",
      "    memory usage, in MiB. It's length is always < timeout / interval\n",
      "    if max_usage is given, returns the two elements maximum memory and\n",
      "    number of measurements effectuated\n",
      "ret : return value of the profiled function\n",
      "    Only returned if retval is set to True\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/memory_profiler.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "memory_profiler.memory_usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib # A must \nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn import model_selection as skms\nfrom sklearn import metrics\nfrom sklearn import neighbors\nfrom sklearn import naive_bayes\nfrom time import sleep\n\nimport timeit, sys\nimport functools as ft\nimport memory_profiler\n\ndef knn_go(train_ftrs, test_ftrs, train_tgt):\n    knn   = neighbors.KNeighborsClassifier(n_neighbors=3)\n    fit   = knn.fit(train_ftrs, train_tgt)\n    preds = fit.predict(test_ftrs)\n\ndef nb_go(train_ftrs, test_ftrs, train_tgt):\n    nb    = naive_bayes.GaussianNB()\n    fit   = nb.fit(train_ftrs, train_tgt)\n    preds = fit.predict(test_ftrs)\n\ndef split_data(dataset):\n    split = skms.train_test_split(dataset.data,\n                                  dataset.target,\n                                  test_size=.25)\n    return split[:-1] # don't need test tgt\n\ndef msr_time(go, args):\n\n    tu = min(timeit.Timer(call).repeat(repeat=3, number=100))\n    print(\"{:<6}: ~{:.4f} sec\".format(go.__name__, tu))\n\ndef msr_mem(go, args):\n    base = memory_profiler.memory_usage()[0]\n    mu = memory_profiler.memory_usage((go, args),\n                                       max_usage=True)\n    print(\"{:<3}: ~{:.4f} MiB\".format(go.__name__, mu-base))\n\nif __name__ == \"__main__\":\n    which_msr = sys.argv[1]\n    which_go = sys.argv[2]\n\n    msr = {'time': msr_time, 'mem':msr_mem}[which_msr]\n    go = {'nb' : nb_go, 'knn': knn_go}[which_go]\n\n    sd = split_data(datasets.load_iris())\n    msr(go, sd)\n"
     ]
    }
   ],
   "source": [
    "!cat scripts/perf_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nb_go: ~0.1797 MiB\n",
      "nb_go : ~0.0687 sec\n"
     ]
    }
   ],
   "source": [
    "!python scripts/perf_01.py mem nb\n",
    "!python scripts/perf_01.py time nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "knn_go: ~0.3477 MiB\n",
      "knn_go: ~0.1662 sec\n"
     ]
    }
   ],
   "source": [
    "!python scripts/perf_01.py mem knn\n",
    "!python scripts/perf_01.py time knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 1. Prove that the emprical probability in the NB model is a maximum likelihood estimation.\n",
    "\n",
    "Ex 2. The similarity of the examples could also be defined by the correlation coefficient:\n",
    "\n",
    "$$\n",
    "r_{ij} = \\frac{\\sum^N_{k=1}(x^{(k)}_{i}-\\overline{x}_i)(x^{(k)}_{j}-\\overline{x}_j)}{[\\sum^N_{k=1}(x^{(k)}_{i}-\\overline{x}_i)^2\\sum^N_{k=1}(x^{(k)}_{j}-\\overline{x}_j)^2]^{\\frac{1}{2}}}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\overline{x}_i = \\frac{1}{N}\\sum^N_{k=1} x^{(k)}_{i},\\quad \\overline{x}_j = \\frac{1}{N}\\sum^N_{k=1} x^{(k)}_{j},\n",
    "$$\n",
    "\n",
    "and $N$ is the number of examples. Inplement with Python a KNN classifier with the similarity above to classify with IRIS data (training test ratio: 75% / 25%). Submit your py file.\n",
    "\n",
    "Ex 3. Discuss the overfitting with NB models. In particular, for the estimation of the conditional probability $P(X=x|Y=c_k)$, if there isn't any example with the input feature $x$ and the label (output feature) $c_k$, the emprical probablity $\\widehat{P}(X=x|Y=c_k)$ will be estimated as $0$, which is in general unreasonable in classification. In this case, how to improve the NB model? Explain your improvement. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}